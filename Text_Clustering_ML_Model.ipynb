{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaraShowCode/Text-Clustering-using-K-Means-and-TF-IDF/blob/main/Text_Clustering_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name** - Netflix Movies and TV Shows Clustering"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type** - Unsupervised ML (Clustering)\n",
        "##### **Contribution** - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on applying unsupervised machine learning, specifically clustering, to the Netflix Movies and TV Shows dataset. The primary objective is to segment the vast content library into distinct groups based on textual features like descriptions, genres, and cast. By doing so, we aim to uncover underlying patterns in the content catalog that can be used to enhance recommendation systems and inform content strategy. The project begins with a rigorous data wrangling phase, where missing values are handled and features are engineered for analysis. A key step in feature engineering is the creation of a 'content soup' by combining multiple text-based columns into a single representative feature for each title. This text data is then converted into a numerical format using the TF-IDF (Term Frequency-Inverse Document Frequency) vectorization technique. To manage the high dimensionality of the resulting data and improve clustering performance, TruncatedSVD is applied for dimensionality reduction. The core of the project is the implementation of the K-Means clustering algorithm. The optimal number of clusters is determined using the Elbow Method. After fitting the model, the resulting clusters are analyzed by examining the top genres and terms within each group to understand their thematic composition. This qualitative analysis reveals distinct and meaningful content segments, such as 'US TV Dramas & Comedies', 'International Dramas & Thrillers', and 'Kids & Family Content'. The project successfully demonstrates how clustering can be used to create a structured, data-driven understanding of a large content library, providing valuable insights for personalization and strategic planning."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix's recommendation engine is a cornerstone of its user experience, but it relies on understanding the nuanced similarities between titles. The business problem is to create a content-based grouping of movies and TV shows using unsupervised machine learning. The goal is to segment the entire Netflix catalog into a predefined number of distinct clusters based on features like genre, description, director, and cast. These clusters can then be used to power a 'similar content' recommendation feature, improve content discovery for users, and provide a high-level overview of the thematic composition of the content library for strategic analysis. The challenge lies in converting the unstructured text data into a meaningful numerical representation and applying a clustering algorithm that can effectively group the titles into coherent and interpretable segments."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries for Data Handling and Visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from collections import Counter\n",
        "from scipy.stats import ttest_ind, chi2_contingency\n",
        "\n",
        "# Import Libraries for Machine Learning\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Set default styles for plots\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 7)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully! \")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df_cleaned = df.copy()\n",
        "print(\"Starting data wrangling...\")\n",
        "\n",
        "# Fill missing categorical data\n",
        "df_cleaned[['director', 'cast', 'country']] = df_cleaned[['director', 'cast', 'country']].fillna('Unknown')\n",
        "\n",
        "# Drop rows with missing date_added or rating (very few)\n",
        "df_cleaned.dropna(subset=['date_added', 'rating'], inplace=True)\n",
        "\n",
        "# Correct date format issue by stripping whitespace\n",
        "df_cleaned['date_added'] = pd.to_datetime(df_cleaned['date_added'].str.strip())\n",
        "\n",
        "# Create the 'content_soup' feature for NLP by combining relevant text columns\n",
        "df_cleaned['content_soup'] = df_cleaned['director'] + ' ' + df_cleaned['cast'] + ' ' + df_cleaned['listed_in'] + ' ' + df_cleaned['description']\n",
        "print(\"Created 'content_soup' feature for clustering.\")\n",
        "print(\"Data wrangling complete. \")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization (Condensed for ML Focus)***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: Distribution of Content Type"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type_counts = df_cleaned['type'].value_counts()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(type_counts, labels=type_counts.index, autopct='%1.1f%%', startangle=140, colors=['#b20710', '#221f1f'])\n",
        "plt.title('Netflix Content Distribution: Movies vs. TV Shows', fontsize=16)\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?\n",
        "A **pie chart** is used here as a quick, high-level overview of the content mix. It effectively shows the proportion of Movies vs. TV Shows.\n",
        "\n",
        "##### 2. What is/are the insight(s) found from the chart?\n",
        "The library consists of approximately 69% Movies and 31% TV Shows, providing essential context for our clustering model.\n",
        "\n",
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Yes, it sets the stage for understanding the different types of content we are about to cluster."
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2: Top 10 Genres on Netflix"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_list = df_cleaned['listed_in'].str.split(', ').sum()\n",
        "top_10_genres = Counter(genre_list).most_common(10)\n",
        "genres_df = pd.DataFrame(top_10_genres, columns=['Genre', 'Count'])\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(data=genres_df, y='Genre', x='Count', palette='mako')\n",
        "plt.title('Top 10 Genres on Netflix', fontsize=16)\n",
        "plt.xlabel('Number of Titles', fontsize=12)\n",
        "plt.ylabel('Genre', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?\n",
        "A **horizontal bar chart** is used to rank the top 10 genres. This is a key visualization because the `listed_in` column is a primary component of our text-based features for clustering.\n",
        "\n",
        "##### 2. What is/are the insight(s) found from the chart?\n",
        "**'International Movies'**, **'Dramas'**, and **'Comedies'** are the most prevalent genres. This suggests that any effective clustering model should be able to separate content based on these dominant themes.\n",
        "\n",
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Yes. Understanding the most common genres helps validate our clustering results later. If our clusters align with these top genres, it indicates the model is capturing meaningful patterns."
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3: Distribution of Content Ratings"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.countplot(data=df_cleaned, x='rating', order=df_cleaned['rating'].value_counts().index, palette='plasma')\n",
        "plt.title('Distribution of Content Ratings on Netflix', fontsize=16)\n",
        "plt.xlabel('Rating', fontsize=12)\n",
        "plt.ylabel('Number of Titles', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?\n",
        "A **count plot** provides a clear view of the distribution of content ratings, which is another key textual feature used in our model.\n",
        "\n",
        "##### 2. What is/are the insight(s) found from the chart?\n",
        "The most common rating is **'TV-MA'** (for mature audiences), followed by **'TV-14'**. This helps characterize the overall tone of the content library.\n",
        "\n",
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Yes, this helps in understanding the target audience of the content we are clustering. We expect to see clusters that align with these different maturity levels."
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=25000)\n",
        "tfidf_matrix = tfidf.fit_transform(df_cleaned['content_soup'])\n",
        "\n",
        "print(f\"Shape of the TF-IDF matrix: {tfidf_matrix.shape}\")"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?\n",
        "**TF-IDF (Term Frequency-Inverse Document Frequency)** was used because it is a powerful technique for converting text into a meaningful numerical representation for machine learning. Unlike simple word counts, TF-IDF gives higher weight to words that are frequent in a single document but rare across all documents, effectively highlighting the terms that best define a specific movie or TV show."
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, dimensionality reduction is crucial for this project. The TF-IDF matrix has 25,000 columns, which corresponds to 25,000 dimensions. Clustering algorithms perform poorly in such high-dimensional spaces due to the 'curse of dimensionality,' where distances between points become less meaningful. By reducing the dimensions, we can capture the most significant patterns in the data while making the clustering process more computationally efficient and effective."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensionality Reduction\n",
        "svd = TruncatedSVD(n_components=200, random_state=42)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "print(f\"Shape of the reduced matrix: {reduced_matrix.shape}\")"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why?\n",
        "**TruncatedSVD** was used for dimensionality reduction. It is a technique similar to Principal Component Analysis (PCA) but is specifically designed to work efficiently with the large, sparse matrices generated by TF-IDF. It effectively reduces the number of features while retaining the maximum amount of variance (i.e., information) from the original data."
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: K-Means Clustering"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we determine the optimal number of clusters using the Elbow Method.\n",
        "inertia = []\n",
        "k_range = range(2, 16)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(reduced_matrix)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the elbow curve\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(k_range, inertia, marker='o', linestyle='--')\n",
        "plt.title('Elbow Method for Optimal k', fontsize=16)\n",
        "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
        "plt.ylabel('Inertia', fontsize=12)\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "elbow_final_final_final"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "optimal_k = 10 # Determined from the elbow plot\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "\n",
        "# Fit the Algorithm\n",
        "kmeans.fit(reduced_matrix)\n",
        "\n",
        "# Predict on the model (assign cluster labels)\n",
        "df_cleaned['cluster'] = kmeans.labels_\n",
        "\n",
        "print(f\"Successfully clustered the data into {optimal_k} clusters.\")"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart - Silhouette Score\n",
        "score = silhouette_score(reduced_matrix, kmeans.labels_)\n",
        "print(f\"Silhouette Score: {score:.4f}\")\n",
        "\n",
        "# Qualitative Analysis: Show the top genres in a few sample clusters\n",
        "for i in range(optimal_k):\n",
        "    cluster_df = df_cleaned[df_cleaned['cluster'] == i]\n",
        "    cluster_genres = cluster_df['listed_in'].str.split(', ').sum()\n",
        "    top_genres = Counter(cluster_genres).most_common(5)\n",
        "    print(f\"\\n--- Cluster {i} (Size: {len(cluster_df)}) Top Genres ---\")\n",
        "    print(top_genres)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explanation of Performance:\n",
        "**K-Means Clustering** was used to partition the data into 10 groups. Since this is an unsupervised task, performance is judged on interpretability and cluster separation.\n",
        "\n",
        "1. **Silhouette Score:** The model achieved a low positive score. In high-dimensional text data, low scores are common and do not necessarily mean the clusters are bad. It suggests that the clusters are not perfectly dense and well-separated, which is expected with complex data like movie descriptions.\n",
        "\n",
        "2. **Qualitative Analysis (Most Important):** The true performance is seen by inspecting the clusters. The analysis of top genres reveals distinct and meaningful themes:\n",
        "   - **Cluster 0:** Dominated by US TV Shows, particularly Dramas and Comedies.\n",
        "   - **Cluster 1:** Clearly represents Stand-Up Comedy specials.\n",
        "   - **Cluster 2 & 3:** Focus on International Movies, especially Dramas.\n",
        "   - **Cluster 4:** Appears to be a large cluster for Documentaries.\n",
        "   - **Cluster 7:** Strong theme of Kids' TV and children's content.\n",
        "\n",
        "This clear thematic separation shows that the model has successfully learned the underlying structure of the content library, which is a strong indicator of good performance for this business problem."
      ],
      "metadata": {
        "id": "kmeans_final_final_final_explain"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this unsupervised learning project, the focus was on implementing and thoroughly analyzing one robust clustering algorithm, K-Means. Other algorithms could be used for comparison in future work:\n",
        "\n",
        "* **Agglomerative Clustering:** A hierarchical approach that builds a tree of clusters. It can be useful for visualizing relationships but is more computationally expensive.\n",
        "* **DBSCAN:** A density-based algorithm that is excellent at finding arbitrarily shaped clusters and identifying outliers. It does not require specifying the number of clusters beforehand but is sensitive to its parameters."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important evaluation metric for a positive business impact is **Qualitative Cluster Analysis**. While the **Silhouette Score** provides a useful quantitative measure of cluster density, its absolute value is often difficult to interpret in a business context. The real value comes from inspecting the clusters themselves.\n",
        "\n",
        "By examining the top genres, keywords, and representative titles within each cluster, we can assign a meaningful theme to each group (e.g., 'US TV Dramas', 'International Thrillers', 'Stand-up Comedy'). This **interpretability** is what allows the business to act on the results. These themed clusters can be directly used to build recommendation carousels ('Because you watched X, you might like these other titles in the *International Thrillers* group') and to analyze content gaps in the library."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fitted models and vectorizer\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
        "joblib.dump(svd, 'svd_model.pkl')\n",
        "joblib.dump(kmeans, 'kmeans_model.pkl')\n",
        "print(\"Models and vectorizer saved successfully.\")"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "loaded_tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
        "loaded_svd = joblib.load('svd_model.pkl')\n",
        "loaded_kmeans = joblib.load('kmeans_model.pkl')\n",
        "\n",
        "# Create a new, unseen movie description\n",
        "unseen_movie = \"An American spy goes on a secret mission in Europe to stop a global conspiracy. Full of action and suspense.\"\n",
        "\n",
        "# Follow the same transformation pipeline\n",
        "unseen_tfidf = loaded_tfidf.transform([unseen_movie])\n",
        "unseen_reduced = loaded_svd.transform(unseen_tfidf)\n",
        "prediction = loaded_kmeans.predict(unseen_reduced)\n",
        "\n",
        "print(f\"--- Sanity Check ---\")\n",
        "print(f\"The unseen movie was assigned to Cluster: {prediction[0]}\")"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project successfully demonstrated the power of unsupervised machine learning to bring structure and insight to a large, unstructured content library. By combining NLP techniques like TF-IDF with K-Means clustering, we were able to segment the entire Netflix catalog into 10 distinct and interpretable groups. The analysis of these clusters revealed clear thematic patterns, such as the separation of international dramas, US-based TV shows, documentaries, and children's content.\n",
        "\n",
        "The primary business value of this work lies in its direct application to content recommendation and strategic analysis. The created clusters can be immediately used to power a 'content-based' recommendation engine, suggesting similar titles to users based on the thematic group of what they just watched. Furthermore, by analyzing the size and composition of these clusters, Netflix can gain a high-level understanding of its content portfolio, identify potential gaps, and make more data-driven decisions about which content areas to invest in next.\n",
        "\n",
        "In conclusion, this project provides not just a model, but a repeatable framework for understanding and segmenting a content library, turning unstructured text data into a valuable strategic asset."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}